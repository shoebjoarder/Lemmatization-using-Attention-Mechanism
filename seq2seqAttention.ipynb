{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597393394594",
   "display_name": "Python 3.8.3 64-bit ('transformers': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "from utils import process_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/fra-eng.csv\", sep=\"\\t\" , header=0, names=[\"InputText\", \"OutputText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                InputText  \\\n135836  Une empreinte carbone est la somme de pollutio...   \n135837  La mort est une chose qu'on nous décourage sou...   \n135838  Puisqu'il y a de multiples sites web sur chaqu...   \n135839  Si quelqu'un qui ne connaît pas vos antécédent...   \n135840  Il est peut-être impossible d'obtenir un Corpu...   \n\n                                               OutputText  \n135836  A carbon footprint is the amount of carbon dio...  \n135837  Death is something that we're often discourage...  \n135838  Since there are usually multiple websites on a...  \n135839  If someone who doesn't know your background sa...  \n135840  It may be impossible to get a completely error...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>InputText</th>\n      <th>OutputText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>135836</th>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n    </tr>\n    <tr>\n      <th>135837</th>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n      <td>Death is something that we're often discourage...</td>\n    </tr>\n    <tr>\n      <th>135838</th>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n      <td>Since there are usually multiple websites on a...</td>\n    </tr>\n    <tr>\n      <th>135839</th>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n      <td>If someone who doesn't know your background sa...</td>\n    </tr>\n    <tr>\n      <th>135840</th>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n      <td>It may be impossible to get a completely error...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.4)\n",
    "valid, test = train_test_split(valid, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_json(\"./data/train.json\", orient=\"records\", lines=True)\n",
    "valid.to_json(\"./data/valid.json\", orient=\"records\", lines=True)\n",
    "test.to_json(\"./data/test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_input = spacy.load(\"fr\")\n",
    "spacy_output = spacy.load(\"en\")\n",
    "\n",
    "def tokenize_input(text):\n",
    "    return [token.text for token in spacy_input.tokenizer(text)]\n",
    "\n",
    "def tokenize_output(text):\n",
    "    return [token.text for token in spacy_output.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = Field(init_token=\"<sos>\", eos_token=\"<eos>\", tokenize=tokenize_input, lower=True)\n",
    "outputText = Field(init_token=\"<sos>\", eos_token=\"<eos>\", tokenize=tokenize_output, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\"InputText\": (\"inputText\", inputText), \"OutputText\": (\"outputText\", outputText)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = TabularDataset.splits(\n",
    "    path=\"data\", train=\"train.json\", test=\"valid.json\", format=\"json\", fields=fields\n",
    ")\n",
    "\n",
    "test_data = TabularDataset.splits(\n",
    "    path=\"data\", test=\"test.json\", format=\"json\", fields=fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "outputText.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, inputText):\n",
    "        src_mask = inputText.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, inputText, outputText):\n",
    "        src_seq_length, N = inputText.shape\n",
    "        trg_seq_length, N = outputText.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(inputText) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(outputText) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(inputText)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're ready to define everything we need for training our Seq2Seq model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(inputText.vocab)\n",
    "trg_vocab_size = len(outputText.vocab)\n",
    "embedding_size = 512    # default: 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3  # 6 in paper\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = inputText.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.inputText),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch = next(iter(train_iterator))\n",
    "# print(batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = inputText.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "\n",
    "sentence = \"Qu’est-ce que vous aimez faire pendant votre temps libre?\"  # french\n",
    "# sentence = \"ein pferd geht unter einer brücke neben einem boot.\"    # german\n",
    "# sentence = \"A horse is standing under a bridge beside a boat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[Epoch 0 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['fear', 'reply', 'court', 'chubby', 'chubby', 'resembles', 'memory', 'grinning', 'gift', 'resembles']\n[Epoch 1 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['would', 'you', 'like', 'you', 'like', 'to', 'do', 'your', 'time', '?']\n[Epoch 2 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['would', 'you', '<unk>', 'you', 'like', 'to', 'do', 'your', 'time', 'time']\n[Epoch 3 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['would', '<unk>', '<unk>', 'you', 'like', 'to', 'do', 'your', 'free', 'time']\n[Epoch 4 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['will', '<unk>', 'think', 'you', 'like', 'to', 'do', 'your', 'free', 'time']\n[Epoch 5 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['would', 'you', '<unk>', 'that', 'you', 'love', 'your', 'time', 'free', 'time']\n[Epoch 6 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', 'you', 'only', 'you', 'like', 'doing', 'during', 'your', 'time', '?']\n[Epoch 7 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['what', 'do', 'you', 'like', 'to', 'do', 'for', 'your', 'time', 'doing']\n[Epoch 8 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'want', 'to', 'do', 'in', 'your', 'free', 'time', '?']\n[Epoch 9 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'you', 'like', 'doing', 'in', 'your', 'free', 'time', '?']\n[Epoch 10 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'like', 'to', 'enjoy', 'doing', 'while', 'your', 'spare', 'time']\n[Epoch 11 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'you', 'enjoy', 'doing', 'during', 'your', 'free', 'time', '?']\n[Epoch 12 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'you', 'enjoy', 'doing', 'in', 'your', 'free', 'time', '?']\n[Epoch 13 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['will', 'you', 'vote', 'until', 'you', 'like', 'your', 'free', 'time', '?']\n[Epoch 14 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'to', 'do', 'in', 'your', 'free']\n[Epoch 15 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'doing', 'in', 'your', 'free', 'time']\n[Epoch 16 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', '<unk>', 'you', 'like', 'doing', 'in', 'your', 'free', 'time']\n[Epoch 17 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['will', 'you', 'like', 'to', 'do', 'your', 'free', 'time', '?', '<eos>']\n[Epoch 18 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'mind', 'turning', 'doing', 'your', 'free', 'time', '?', '<eos>']\n[Epoch 19 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'enjoy', 'pretending', 'you', 'like', 'doing', 'in', 'your', 'free']\n[Epoch 20 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'like', 'to', 'do', 'this', 'in', 'your', 'free', 'time']\n[Epoch 21 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'think', 'you', 'like', 'to', 'do', 'your', 'free', 'time']\n[Epoch 22 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['what', 'do', 'you', 'like', 'to', 'do', 'in', 'your', 'free', 'time']\n[Epoch 23 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'think', 'you', 'like', 'to', 'do', 'in', 'your', 'spare']\n[Epoch 24 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'wish', 'you', 'had', 'served', 'in', 'your', 'free', 'time']\n[Epoch 25 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'doing', 'in', 'your', 'free', 'time']\n[Epoch 26 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'enjoy', 'doing', 'in', 'your', 'free', 'time']\n[Epoch 27 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'to', 'do', 'in', 'your', 'spare']\n[Epoch 28 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'to', 'do', 'in', 'your', 'free']\n[Epoch 29 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'to', 'do', 'in', 'your', 'free']\n[Epoch 30 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'enjoy', 'doing', 'for', 'your', 'free', 'time']\n[Epoch 31 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['will', 'you', 'continue', 'you', 'like', 'to', 'do', 'in', 'your', 'spare']\n[Epoch 32 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'think', 'you', 'like', 'to', 'do', 'in', 'your', 'free']\n[Epoch 33 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['do', 'you', 'think', 'you', 'like', 'to', 'do', 'in', 'your', 'spare']\n[Epoch 34 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'like', 'to', 'do', 'in', 'your', 'free']\n[Epoch 35 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'you', 'like', 'to', 'do', 'in', 'your', 'free', 'time']\n[Epoch 36 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'enjoy', 'doing', 'in', 'your', 'free', 'time']\n[Epoch 37 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['what', 'do', 'you', 'like', 'to', 'do', 'in', 'your', 'free', 'time']\n[Epoch 38 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['what', 'do', 'you', 'like', 'to', 'do', 'in', 'your', 'free', 'time']\n[Epoch 39 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['what', 'do', 'you', 'like', 'to', 'do', 'in', 'your', 'free', 'time']\n[Epoch 40 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['what', 'do', 'you', 'like', 'to', 'do', 'in', 'your', 'free', 'time']\n[Epoch 41 / 1000]\n=> Saving checkpoint\nLemmatize example sentence: \n ['<unk>', '<unk>', 'what', 'you', 'enjoy', 'doing', 'in', 'your', 'free', 'time']\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-40057d4ae1bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Gradient descent step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# plot to tensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\shoeb\\Desktop\\Projects\\virtualEnvs\\transformers\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\shoeb\\Desktop\\Projects\\virtualEnvs\\transformers\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "    processed_sentence = process_sentence(\n",
    "        model, sentence, inputText, outputText, device, max_length=10\n",
    "    )\n",
    "\n",
    "    print(f\"Predicted sentence: \\n {processed_sentence}\")\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.inputText.to(device)\n",
    "        target = batch.outputText.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin.\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)"
   ]
  }
 ]
}