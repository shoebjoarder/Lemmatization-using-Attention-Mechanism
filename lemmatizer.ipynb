{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597476117886",
   "display_name": "Python 3.8.3 64-bit ('transformers': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import stanza\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 9.60MB/s]\n2020-08-15 12:35:46 INFO: Downloading default packages for language: en (English)...\n2020-08-15 12:35:47 INFO: File exists: C:\\Users\\shoeb\\stanza_resources\\en\\default.zip.\n2020-08-15 12:35:50 INFO: Finished downloading models and saved to C:\\Users\\shoeb\\stanza_resources.\n2020-08-15 12:35:50 INFO: Loading these models for language: en (English):\n=========================\n| Processor | Package   |\n-------------------------\n| tokenize  | ewt       |\n| pos       | ewt       |\n| lemma     | ewt       |\n| depparse  | ewt       |\n| sentiment | sstplus   |\n| ner       | ontonotes |\n=========================\n\n2020-08-15 12:35:51 INFO: Use device: gpu\n2020-08-15 12:35:51 INFO: Loading: tokenize\n2020-08-15 12:35:56 INFO: Loading: pos\n2020-08-15 12:35:57 INFO: Loading: lemma\n2020-08-15 12:35:57 INFO: Loading: depparse\n2020-08-15 12:35:58 INFO: Loading: sentiment\n2020-08-15 12:35:59 INFO: Loading: ner\n2020-08-15 12:36:00 INFO: Done loading processors!\n"
    }
   ],
   "source": [
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en')\n",
    "spacyToken = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         id                                           sentence\n9153   9996  The wounded soldiers were taken to a local hos...\n9154   9997  On Thursday, the BART Board is scheduled to co...\n9155   9998           The other problem is the lack of organs.\n9156   9999  Analysts are calling for earnings of 59 cents ...\n9157  10000                        It's a thinking experience.",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9153</th>\n      <td>9996</td>\n      <td>The wounded soldiers were taken to a local hos...</td>\n    </tr>\n    <tr>\n      <th>9154</th>\n      <td>9997</td>\n      <td>On Thursday, the BART Board is scheduled to co...</td>\n    </tr>\n    <tr>\n      <th>9155</th>\n      <td>9998</td>\n      <td>The other problem is the lack of organs.</td>\n    </tr>\n    <tr>\n      <th>9156</th>\n      <td>9999</td>\n      <td>Analysts are calling for earnings of 59 cents ...</td>\n    </tr>\n    <tr>\n      <th>9157</th>\n      <td>10000</td>\n      <td>It's a thinking experience.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/english.txt\", sep=\"\\t\", header=None, names=[\"id\", \"sentence\"])\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [token.text for token in spacyToken.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortSentence(text, size):\n",
    "    tokens = text[:size]\n",
    "    sentence = \"\"\n",
    "    for txt in tokens:\n",
    "        sentence = sentence + txt + \" \"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 9158/9158 [00:01<00:00, 5310.28it/s]\n"
    }
   ],
   "source": [
    "shortText = {'sentence':[]}\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = tokenize(df['sentence'][i])\n",
    "    text = shortSentence(text, 60)\n",
    "    shortText['sentence'].append(text.rstrip())\n",
    "shortText = pd.DataFrame(shortText)\n",
    "shortText.to_csv(r'./data/eng-shortText.txt', sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               sentence\n9154  The wounded soldiers were taken to a local hos...\n9155  On Thursday , the BART Board is scheduled to c...\n9156          The other problem is the lack of organs .\n9157  Analysts are calling for earnings of 59 cents ...\n9158                      It 's a thinking experience .",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9154</th>\n      <td>The wounded soldiers were taken to a local hos...</td>\n    </tr>\n    <tr>\n      <th>9155</th>\n      <td>On Thursday , the BART Board is scheduled to c...</td>\n    </tr>\n    <tr>\n      <th>9156</th>\n      <td>The other problem is the lack of organs .</td>\n    </tr>\n    <tr>\n      <th>9157</th>\n      <td>Analysts are calling for earnings of 59 cents ...</td>\n    </tr>\n    <tr>\n      <th>9158</th>\n      <td>It 's a thinking experience .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/eng-shortText.txt\", sep=\"\\t\", header=None, names=[\"sentence\"])\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Maximum number of tokens in the dataset: 61\n"
    }
   ],
   "source": [
    "token_lens = []\n",
    "a = 0\n",
    "for txt in df.sentence:\n",
    "  tokens = tokenize(txt)\n",
    "  b = len(tokens)\n",
    "  if b > a:\n",
    "    a = b\n",
    "  token_lens.append(len(tokens))\n",
    "print(\"Maximum number of tokens in the dataset:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLemmatization(text):\n",
    "    word = \"\"\n",
    "    lemma = \"\"\n",
    "    punc= set(string.punctuation)\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sentences:\n",
    "        for wrd in sent.words:\n",
    "            c = str(wrd.text)\n",
    "            d = str(wrd.lemma)\n",
    "            if any(char in punc for char in d)==True:\n",
    "                word = word.lstrip()\n",
    "                lemma = lemma.lstrip()\n",
    "                word += c + \" \"\n",
    "                lemma += d + \" \"\n",
    "            else:\n",
    "                word += c + \" \"\n",
    "                lemma += d + \" \"\n",
    "    return word, lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 9159/9159 [12:26<00:00, 12.27it/s]\n"
    }
   ],
   "source": [
    "parsed_text = {'sentence':[], 'lemma':[]}\n",
    "for i in tqdm(range(len(df))):\n",
    "    word, lemma = processLemmatization(df['sentence'][i])\n",
    "    #extract text and lemma\n",
    "    parsed_text['sentence'].append(word.rstrip())\n",
    "    parsed_text['lemma'].append(lemma.rstrip())\n",
    "text = pd.DataFrame(parsed_text)\n",
    "# text.to_csv(r'./data/eng-lem.txt', sep='\\t', index = False)\n",
    "text.to_csv(r'./data/eng-lem.txt', sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                                                             sentence\nThe wounded soldiers were taken to a local hosp...  the wounded soldier be take to a local hospita...\nOn Thursday , the BART Board is scheduled to co...  on Thursday , the BART Board be schedule to co...\nThe other problem is the lack of organs .                    the other problem be the lack of organ .\nAnalysts are calling for earnings of 59 cents a...  analyst be call for earning of 59 cent a share...\nIt 's a thinking experience .                                           it be a thinking experience .",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>The wounded soldiers were taken to a local hospital , the official said .</th>\n      <td>the wounded soldier be take to a local hospita...</td>\n    </tr>\n    <tr>\n      <th>On Thursday , the BART Board is scheduled to consider proposals to raise fees and charge for parking at stations throughout the system in Berkeley and Oakland .</th>\n      <td>on Thursday , the BART Board be schedule to co...</td>\n    </tr>\n    <tr>\n      <th>The other problem is the lack of organs .</th>\n      <td>the other problem be the lack of organ .</td>\n    </tr>\n    <tr>\n      <th>Analysts are calling for earnings of 59 cents a share . After the bell , Genentech will reveal its first - quarter results .</th>\n      <td>analyst be call for earning of 59 cent a share...</td>\n    </tr>\n    <tr>\n      <th>It 's a thinking experience .</th>\n      <td>it be a thinking experience .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/eng-lem.txt\", sep=\"\\t\", header=None, names=[\"sentence\"])\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}