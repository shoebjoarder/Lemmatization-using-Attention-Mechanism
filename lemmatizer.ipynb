{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597395802491",
   "display_name": "Python 3.8.3 64-bit ('transformers': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import stanza\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 20.4MB/s]\n2020-08-14 12:00:04 INFO: Downloading default packages for language: en (English)...\n2020-08-14 12:00:04 INFO: File exists: C:\\Users\\shoeb\\stanza_resources\\en\\default.zip.\n2020-08-14 12:00:08 INFO: Finished downloading models and saved to C:\\Users\\shoeb\\stanza_resources.\nINFO: Pandarallel will run on 12 workers.\nINFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
    }
   ],
   "source": [
    "stanza.download('en')\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-08-14 12:00:08 INFO: Loading these models for language: en (English):\n=========================\n| Processor | Package   |\n-------------------------\n| tokenize  | ewt       |\n| pos       | ewt       |\n| lemma     | ewt       |\n| depparse  | ewt       |\n| sentiment | sstplus   |\n| ner       | ontonotes |\n=========================\n\n2020-08-14 12:00:08 INFO: Use device: gpu\n2020-08-14 12:00:08 INFO: Loading: tokenize\n2020-08-14 12:00:12 INFO: Loading: pos\n2020-08-14 12:00:12 INFO: Loading: lemma\n2020-08-14 12:00:12 INFO: Loading: depparse\n2020-08-14 12:00:14 INFO: Loading: sentiment\n2020-08-14 12:00:15 INFO: Loading: ner\n2020-08-14 12:00:15 INFO: Done loading processors!\n"
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/english.txt\", sep=\"\\t\", header=0, names=[\"id\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id                                           sentence\n0   2  You would be a great client for Southern India...\n1   3  He believes the 21st century will be the \"cent...\n2   4  They even call the civil rights organization a...\n3   5  But while VRE is not a threat to healthy indiv...\n4   6  Earlier on Tuesday, roadside bombs, including ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>You would be a great client for Southern India...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>He believes the 21st century will be the \"cent...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>They even call the civil rights organization a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>But while VRE is not a threat to healthy indiv...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>Earlier on Tuesday, roadside bombs, including ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLemmatization(text):\n",
    "    word = \"\"\n",
    "    lemma = \"\"\n",
    "    punc= set(string.punctuation)\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sentences:\n",
    "        for wrd in sent.words:\n",
    "            c = str(wrd.text)\n",
    "            d = str(wrd.lemma)\n",
    "            if any(char in punc for char in d)==True:\n",
    "                word = word.lstrip()\n",
    "                lemma = lemma.lstrip()\n",
    "                word += c + \" \"\n",
    "                lemma += d + \" \"\n",
    "            else:\n",
    "                word += c + \" \"\n",
    "                lemma += d + \" \"  \n",
    "    #return a dataframe\n",
    "    return word, lemma\n",
    "    # return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 9157/9157 [12:36<00:00, 12.10it/s]\n"
    }
   ],
   "source": [
    "parsed_text = {'sentence':[], 'lemma':[]}\n",
    "for i in tqdm(range(len(df))):\n",
    "    word, lemma = processLemmatization(df['sentence'][i])\n",
    "    #extract text and lemma\n",
    "    parsed_text['sentence'].append(word.rstrip())\n",
    "    parsed_text['lemma'].append(lemma.rstrip())\n",
    "text = pd.DataFrame(parsed_text)\n",
    "text.to_csv(r'./data/eng-lem.txt', sep='\\t', index = False)"
   ]
  }
 ]
}